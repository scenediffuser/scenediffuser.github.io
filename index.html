<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>SceneDiffuser</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <style>
    body {
      background-color: #fafafa;
    }
    hr {
      background-color: #f1f1f1;
    }
    .table th {
      padding: 0.2em 0.2em 0 0.2em;
      width: 50%;
    }
    .table td {
      padding: 0.25em;
      width: 50%;
    }
    .content-block {
      padding: 0 6px;
    }
    .title {
      font-size: 32px;
      padding-top: 32px;
    }
    .publisher {
      margin-bottom: 1rem;
    }
    .sub-title {
      font-size: 26px;
      padding-bottom: 16px;
    }
    .subsub-title {
      font-size: 20px;
      padding-bottom: 8px;
    }
    .author {
      font-size: 16px;
    }
    .task {
      padding-bottom: 12px;
    }
  </style>
  <script type="importmap">
    {
      "imports": {
        "vue": "https://unpkg.com/vue@3/dist/vue.esm-browser.js",
        "three": "https://unpkg.com/three@0.127.0/build/three.module.js",
        "three/addons/": "https://unpkg.com/three@0.127.0/examples/jsm/"
      }
    }
  </script>
</head>

<body>
  <div id="app">
    <div class="columns">
      <div class="column" :class="[content, offset]">

        <h1 class="title has-text-centered" style="margin-bottom: 0.5em">
          Diffusion-based Generation, Optimization, and Planning in 3D Scenes
        </h1>

        <!-- <p class="publisher has-text-centered">Conference</p> -->

        <div class="has-text-centered" style="padding: 0 2em;">

          <p class="author">
            <a href="https://siyuanhuang.com/">Siyuan Huang</a><sup>1✶</sup> &nbsp;&nbsp;&nbsp;
            <a href="https://silvester.wang">Zan Wang</a><sup>1,2✶</sup> &nbsp;&nbsp;&nbsp;
            <a href="https://xiaoyao-li.github.io/">Puhao Li</a><sup>1,3</sup> &nbsp;&nbsp;&nbsp;
            <a href="https://buzz-beater.github.io/">Baoxiong Jia</a><sup>1</sup><br>
            <a href="http://tengyu.ai/">Tengyu Liu</a><sup>1</sup> &nbsp;&nbsp;&nbsp;
            <a href="https://yzhu.io/">Yixin Zhu</a><sup>4</sup> &nbsp;&nbsp;&nbsp;
            <a href="https://liangwei-bit.github.io/web/">Wei Liang</a><sup>2</sup> &nbsp;&nbsp;&nbsp;
            <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a><sup>1,3,4</sup>
          </p>

          <p style="font-size: 0.9em; padding: 0.5em 0;">✶ indicates equal contribution</p>

          <p style="font-size: 1em;">
            <sup>1</sup>National Key Laboratory of General Artificial Intelligence, BIGAI<br>
            <sup>2</sup>School of Computer Science & Technology, Beijing Institute of Technology<br>
            <sup>3</sup>Dept. of Automation, Tsinghua University&nbsp;&nbsp;&nbsp;<sup>4</sup>Institute for AI, Peking University<br>
          </p>

          <div style="margin: 1em 0; font-size: 1.1em;">
            <p> <a href="https://arxiv.org/abs/2301.06015">arXiv</a> &nbsp;|&nbsp; <a href="https://huggingface.co/spaces/SceneDiffuser/SceneDiffuserDemo">Huggingface Space</a></p>
          </div>
        </div>

        <div class="has-text-centered" style="padding: 0 1em;">
          <img src="./assets/teaser.png"/>
          <p style="text-align: justify; font-size: 0.8em;">We introduce <b>SceneDiffuser</b>, a conditional generative model for 3D scene understanding. <b>SceneDiffuser</b> is applicable to various scene-conditioned 3D tasks: (a)<span style="color: #48B3B3;">human pose generation</span>, (b) <span style="color: #9F47B3;">human motion generation</span>, (c) <span style="color: #8FB300;">dexterous grasp generation</span>, (d) <span style="color: #3B4FB3">path planning for 3D navigation</span> with <span style="color: #B30000">goals</span>, and (e) <span style="color: #00B353">motion planning for robot arms</span>.</p>
        </div>

        <hr>

        <div class="has-text-centered content-block">
          <h2 class="sub-title">Abstract</h2>
          <p style="text-align:justify; margin-bottom: 1.5em;">
            We introduce SceneDiffuser, a conditional generative model for 3D scene understanding. SceneDiffuser provides a unified model for solving scene-conditioned generation, optimization, and planning. In contrast to prior works, SceneDiffuser is intrinsically scene-aware, physics-based, and goal-oriented. With an iterative sampling strategy, SceneDiffuser jointly formulates the scene-aware generation, physics-based optimization, and goal-oriented planning via a diffusion-based denoising process in a fully differentiable fashion. Such a design alleviates the discrepancies among different modules and the posterior collapse of previous scene-conditioned generative models. We evaluate SceneDiffuser with various 3D scene understanding tasks, including human pose and motion generation, dexterous grasp generation, path planning for 3D navigation, and motion planning for robot arms. The results show significant improvements compared with previous models, demonstrating the tremendous potential of SceneDiffuser for the broad community of 3D scene understanding.
          </p>

          <video controls="controls" loop="loop" autoplay="autoplay" style="padding: 0 5em;">
            <source src="./assets/illustration-720.mp4" type="video/mp4">
          </video>
        </div>

        <hr>

        <div id="results" class="content-block">
          <h2 class="sub-title has-text-centered">Human Pose Generation in 3D Scenes</h2>

          <div class="task">
            <div class="columns is-centered" style="position: relative;">
              <div class="control" style="position: absolute; left: 3%;">
                <label class="radio">
                  <input value="MPH1Library" type="radio" name="scene"> MPH1Library
                </label>
                <br>
                <label class="radio">
                  <input value="MPH16" type="radio" name="scene"> MPH16
                </label>
                <br>
                <label class="radio">
                  <input value="N0SittingBooth" type="radio" name="scene"> N0SittingBooth
                </label>
                <br>
                <label class="radio">
                  <input value="N3OpenArea" type="radio" name="scene"> N3OpenArea
                </label>
              </div>
              <div id="pose_loading" style="position: absolute; left: 50%; top: 45%;"></div>
              <canvas id="webgl_pose" style="height: 50%; width: 50%;"></canvas>
            </div>
            <p style="margin: 0 1.5em; font-size: 0.8em; text-align:justify;">Note: Click the radio button to select a scene for result visualization and drag to move your view around.</p>
          </div>
        </div>

        <hr>

        <div class="content-block">
          <h2 class="sub-title has-text-centered">Dexterous Grasp Generation for 3D Objects</h2>
          
          <div class="task">
            <div class="columns is-centered" style="position: relative;">
              <div style="position: absolute; left: 3%; top: 3%;">
                <span style="font-size: 0.8em;">Object </span>
                <div class="select is-small">
                  <select id="objectSelector">
                    <option>contactdb+apple</option>
                    <option>contactdb+camera</option>
                    <option>contactdb+cylinder_medium</option>
                    <option>contactdb+door_knob</option>
                    <option>contactdb+rubber_duck</option>
                    <option>contactdb+water_bottle</option>
                    <option>ycb+baseball</option>
                    <option>ycb+pear</option>
                    <option>ycb+potted_meat_can</option>
                    <option>ycb+tomato_soup_can</option>
                  </select>
                </div>
                &nbsp;&nbsp;&nbsp;
                <span style="font-size: 0.8em;">Sample </span>
                <div class="select is-small">
                  <select id="sampleSelector">
                    <option>grasp_0</option>
                    <option>grasp_1</option>
                    <option>grasp_2</option>
                    <option>grasp_3</option>
                    <option>grasp_4</option>
                    <option>grasp_5</option>
                    <option>grasp_6</option>
                    <option>grasp_7</option>
                    <option>grasp_8</option>
                    <option>grasp_9</option>
                  </select>
                </div>
              </div>
              <div id="grasp_loading" style="position: absolute; left: 50%; top: 45%;"></div>
              <canvas id="webgl_grasp" style="height: 50%; width: 50%;"></canvas>
            </div>
            <p style="margin: 0 1.5em; font-size: 0.8em; text-align:justify;">Note: Click the select dropdown to select a object and a pre-sampled grasp for result visualization. Drag to move your view around.</p>
          </div>
        </div>

        <hr>

        <div class="content-block">
          <h2 class="sub-title has-text-centered">Human Motion Generation in 3D Scenes</h2>
          
          <div class="task">
            <table class="table is-bordered my-table" style="margin: 0 1em;">
              <tbody>
                <tr>
                  <th class="has-text-centered">
                    N0SittingBooth
                  </th>
                  <th class="has-text-centered">
                    N3OpenArea
                  </th>
                </tr>
                <tr>
                  <td>
                    <video controls="controls" loop="loop" autoplay="autoplay">
                      <source src="./assets/motion_generation/s1_1.mp4" type="video/mp4">
                    </video>
                  </td>
                  <td>
                    <video controls="controls" loop="loop" autoplay="autoplay">
                      <source src="./assets/motion_generation/s2_1.mp4" type="video/mp4">
                    </video>
                  </td>
                </tr>
                <tr>
                  <td>
                    <video controls="controls" loop="loop" autoplay="autoplay">
                      <source src="./assets/motion_generation/s1_2.mp4" type="video/mp4">
                    </video>
                  </td>
                  <td>
                    <video controls="controls" loop="loop" autoplay="autoplay">
                      <source src="./assets/motion_generation/s2_2.mp4" type="video/mp4">
                    </video>
                  </td>
                </tr>
                <tr>
                  <td>
                    <video controls="controls" loop="loop" autoplay="autoplay">
                      <source src="./assets/motion_generation/s1_3.mp4" type="video/mp4">
                    </video>
                  </td>
                  <td>
                    <video controls="controls" loop="loop" autoplay="autoplay">
                      <source src="./assets/motion_generation/s2_3.mp4" type="video/mp4">
                    </video>
                  </td>
                </tr>
              </tbody>
            </table>
            <p style="margin: 0 1.5em; font-size: 0.8em; text-align:justify;">Note: Each column shows sampled human motions from the same start pose.</p>
          </div>
        </div>

        <hr>

        <div class="content-block">
          <h2 class="sub-title has-text-centered">Path Planning for 3D Scene Navigation</h2>
          
          <div class="task">
            <table class="table is-bordered my-table" style="margin: 0 1em;">
              <tbody>
                <tr>
                  <td>
                    <img src="./assets/path_planning/scene0603_00_N0pT/res_097.png"/>
                  </td>
                  <td>
                    <img src="./assets/path_planning/scene0621_00_cJ4H/res_074.png"/>
                  </td>
                </tr>
                <tr>
                  <td>
                    <img src="./assets/path_planning/scene0634_00_48Y3/res_054.png"/>
                  </td>
                  <td>
                    <img src="./assets/path_planning/scene0641_00_KBKx/res_050.png"/>
                  </td>
                </tr>
                <tr>
                  <td>
                    <img src="./assets/path_planning/scene0645_00_35Hy/res_118.png"/>
                  </td>
                  <td>
                    <img src="./assets/path_planning/scene0678_00_QbNL/res_130.png"/>
                  </td>
                </tr>
                <tr>
                  <td>
                    <img src="./assets/path_planning/scene0694_00_DgAL/res_053.png"/>
                  </td>
                  <td>
                    <img src="./assets/path_planning/scene0698_00_tT3Q/res_074.png"/>
                  </td>
                </tr>
              </tbody>
            </table>
            <p style="margin: 0 1.5em; font-size: 0.8em; text-align:justify;">Note: The red balls represent the planning result, starting with the lightest red ball and ending with the darkest red ball. The green ball indicates the target position.</p>
          </div>
        </div>

        <hr>
        
        <div class="content-block">
          <h2 class="sub-title has-text-centered">Motion Planning for Robot Arms</h2>
          <div class="task">
            <table class="table is-bordered my-table" style="margin: 0 1em;">
              <tbody>
                <tr>
                  <td>
                    <img src="./assets/arm_motion/160-1 00_00_00-00_00_30.gif"/>
                  </td>
                  <td>
                    <img src="./assets/arm_motion/160-4 00_00_00-00_00_30.gif"/>
                  </td>
                </tr>
                <tr>
                  <td>
                    <img src="./assets/arm_motion/161-3 00_00_00-00_00_30.gif"/>
                  </td>
                  <td>
                    <img src="./assets/arm_motion/161-5 00_00_00-00_00_30.gif"/>
                  </td>
                </tr>
                <tr>
                  <td>
                    <img src="./assets/arm_motion/164-1 00_00_00-00_00_30.gif"/>
                  </td>
                  <td>
                    <img src="./assets/arm_motion/164-5 00_00_00-00_00_30.gif"/>
                  </td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>

        <hr>

        <div class="has-text-centered content-block">
          <h2 class="sub-title">Bibtex</h2>
          <p style="text-align:justify">If you find our project useful, please consider citing us:</p>
          <div style="padding-top: 1rem; text-align: left;">
<pre><code>
@article{huang2023diffusion,
  title={Diffusion-based Generation, Optimization, and Planning in 3D Scenes},
  author={Huang, Siyuan and Wang, Zan and Li, Puhao and Jia, Baoxiong and Liu, Tengyu and Zhu, Yixin and Liang, Wei and Zhu, Song-Chun},
  journal={arXiv preprint arXiv:2301.06015},
  year={2023}
}
</code></pre>
          </div>
        </div>

      </div>
    </div>
    
    <footer class="footer" style="padding: 0 0 1.5rem 0">
      <div class="columns">
        <div class="column" :class="[content, offset]">
          <hr>
          <p class="has-text-centered" style="font-size: 0.9em;">This website is designed and coded by the authors. Send feedback and questions to <a href="https://silvester.wang">Zan Wang</a></p>
        </div>
      </div>
    </footer>
  </div>
</body>

<script type="module">
  import { createApp } from 'vue'

  let app = createApp({
    data() {
      return {
        content: 'is-6',
        offset: 'is-offset-3'
      }
    }
  }).mount('#app')

  function displayWindowSize() {
    let w = document.documentElement.clientWidth;
    // console.log(w)
    let c
    let o
    if (w >= 1200) {
      c = 'is-6'
      o = 'is-offset-3'
    } else {
      if (w >= 900) {
        c = 'is-8'
        o = 'is-offset-2'
      } else {
        c = 'is-10'
        o = 'is-offset-1'
      }
    }
    app.$data.content = c
    app.$data.offset = o
  }
  window.addEventListener("resize", displayWindowSize)
  displayWindowSize()

  import * as THREE from 'three'
  import { OrbitControls } from 'three/addons/controls/OrbitControls.js'
  import {GLTFLoader} from 'three/addons/loaders/GLTFLoader.js'

  // pose generation in 3D scene
  let canvas1 = document.querySelector('#webgl_pose')
  let scene1 = new THREE.Scene()
  let assetLoader1 = new GLTFLoader()
  let model1

  let camera1 = new THREE.PerspectiveCamera(45, 1.618 / 1.0, 0.1, 100)
  camera1.position.set(4, 3, -3)
  let grid1 = new THREE.GridHelper(30, 30)
  scene1.add(camera1)
  scene1.add(grid1)
  for (let i = 0; i <= 1; i++) {
    for (let k = 0; k <= 1; k++) {
      let spotLight = new THREE.SpotLight(0xAAAAAA)
      spotLight.position.set(50 * (i * 2 - 1), 100, 100 * (k * 2 - 1))
      scene1.add(spotLight)
    }
  }

  let controls1 = new OrbitControls(camera1, canvas1)
  controls1.enableZoom = true
  // controls2.enableDamping = true
  controls1.object.position.set(camera1.position.x, camera1.position.y, camera1.position.z)
  controls1.target = new THREE.Vector3(0, 0, 0)
  controls1.update()

  let renderer1 = new THREE.WebGLRenderer({
      canvas: canvas1,
      alpha: true,
  })
  renderer1.setPixelRatio(Math.min(window.devicePixelRatio, 2))
  renderer1.outputEncoding = THREE.sRGBEncoding
  renderer1.setAnimationLoop(() => {
    renderer1.render(scene1, camera1)
  });

  const radioButtons = document.querySelectorAll('input[name="scene"]')
  for (const radioButton of radioButtons) {
    radioButton.addEventListener('change', (e) => {
      scene1.remove(model1)
      document.querySelector('#pose_loading').innerHTML = `<img src="./assets/icons/loading.svg" width="48" height="48">`
      for (const rb of radioButtons) {rb.disabled = true}

      let assetUrl = new URL('./assets/pose_generation/'+radioButton.value+'.glb', import.meta.url)
      assetLoader1.load(assetUrl.href, gltf => {
        model1 = gltf.scene
        model1.rotateX(-Math.PI / 2)
        scene1.add(model1)
        document.querySelector('#pose_loading').innerHTML = ''
        for (const rb of radioButtons) {rb.disabled = false}
      }, undefined, (error) => {console.error(error)})
    })
  }
  radioButtons[0].click()

  // grasp generation for 3D object
  let canvas2 = document.querySelector('#webgl_grasp')
  let scene2 = new THREE.Scene()
  let assetLoader2 = new GLTFLoader()
  let model2

  let camera2 = new THREE.PerspectiveCamera(45, 1.618 / 1.0, 0.1, 100)
  camera2.position.set(0.25, 0.2, -0.25)
  let grid2 = new THREE.GridHelper(30, 30)
  scene2.add(camera2)
  scene2.add(grid2)
  for (let ax = 0; ax < 3; ax++) {
    for (let i = 0; i <= 1; i++) {
      let spotLight = new THREE.SpotLight(0xAAAAAA)
      spotLight.position.set(
        ax == 0 ? 50 * (i * 2 - 1): 0,
        ax == 1 ? 50 * (i * 2 - 1): 0,
        ax == 2 ? 50 * (i * 2 - 1): 0,
      )
      scene2.add(spotLight)
    }
  }

  let controls2 = new OrbitControls(camera2, canvas2)
  controls2.enableZoom = true
  // controls2.enableDamping = true
  controls2.object.position.set(camera2.position.x, camera2.position.y, camera2.position.z)
  controls2.target = new THREE.Vector3(0, 0, 0)
  controls2.update()

  let renderer2 = new THREE.WebGLRenderer({
      canvas: canvas2,
      alpha: true,
  })
  renderer2.setPixelRatio(Math.min(window.devicePixelRatio, 2))
  renderer2.outputEncoding = THREE.sRGBEncoding
  renderer2.setAnimationLoop(() => {
    renderer2.render(scene2, camera2)
  });

  const objSel = document.querySelector('#objectSelector')
  const samSel = document.querySelector('#sampleSelector')
  objSel.value = 'ycb+baseball'
  samSel.value = 'grasp_0'

  function load_model2(e) {
    if (objSel.value == '' || samSel.value == '') {
      return
    }
    scene2.remove(model2)
    document.querySelector('#grasp_loading').innerHTML = `<img src="./assets/icons/loading.svg" width="48" height="48">`
    let assetUrl = new URL(`./assets/grasp_generation_color/${objSel.value}/${samSel.value}.glb`, import.meta.url)
    assetLoader2.load(assetUrl.href, gltf => {
      model2 = gltf.scene
      scene2.add(model2)
      document.querySelector('#grasp_loading').innerHTML = ''
    }, undefined, (error) => {console.error(error)})
  }

  objSel.addEventListener('change', (e) => {samSel.value = ''})
  samSel.addEventListener('change', load_model2)
  load_model2()

  // resize renderers
  function resizeRenderers() {
    let content_width = document.querySelector('#results').offsetWidth
    renderer1.setSize(content_width, content_width / 1.618)
    renderer2.setSize(content_width, content_width / 1.618)
  }
  window.addEventListener('resize', () => {
    resizeRenderers()
  })
  resizeRenderers()
</script>

</html>
